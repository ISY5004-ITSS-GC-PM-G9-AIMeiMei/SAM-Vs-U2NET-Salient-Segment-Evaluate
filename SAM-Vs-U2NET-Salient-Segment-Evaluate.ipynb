{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e77bda-bc10-4f8a-9582-dca658bb00d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No numbers missing in the sequence.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import onnxruntime\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "# ---------- Helper Functions ----------\n",
    "\n",
    "def preprocess_for_u2net(image, target_size=(320, 320)):\n",
    "    \"\"\"\n",
    "    Preprocess the image for U2-Net:\n",
    "      - Resize\n",
    "      - Convert BGR to RGB\n",
    "      - Normalize to [0, 1]\n",
    "      - Rearrange to CHW and add batch dimension\n",
    "    \"\"\"\n",
    "    orig_h, orig_w = image.shape[:2]\n",
    "    image_resized = cv2.resize(image, target_size)\n",
    "    image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)\n",
    "    image_norm = image_rgb.astype(np.float32) / 255.0\n",
    "    image_input = np.transpose(image_norm, (2, 0, 1))  # CHW\n",
    "    image_input = np.expand_dims(image_input, axis=0)    # add batch dim\n",
    "    return image_input, (orig_w, orig_h)\n",
    "\n",
    "def postprocess_u2net(prediction, orig_size, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Process U2-Net output:\n",
    "      - Remove batch and channel dimensions\n",
    "      - Resize to original image size\n",
    "      - Binarize using threshold\n",
    "    \"\"\"\n",
    "    # Assuming the model output shape is [1,1,H,W]\n",
    "    pred_mask = prediction[0, 0, :, :]\n",
    "    pred_mask = cv2.resize(pred_mask, orig_size)\n",
    "    pred_mask_bin = (pred_mask > threshold).astype(np.uint8) * 255\n",
    "    return pred_mask_bin\n",
    "\n",
    "def select_largest_mask(masks):\n",
    "    \"\"\"\n",
    "    From SAMâ€™s list of masks, select the one with the largest area.\n",
    "    Each mask in the list is expected to be a dict with a 'segmentation' key.\n",
    "    \"\"\"\n",
    "    if not masks:\n",
    "        return None\n",
    "    areas = [mask['segmentation'].sum() for mask in masks]\n",
    "    largest_mask = masks[np.argmax(areas)]['segmentation']\n",
    "    # Convert boolean mask to 0-255 uint8 image.\n",
    "    return (largest_mask.astype(np.uint8)) * 255\n",
    "\n",
    "def compute_iou(mask_pred, mask_gt):\n",
    "    \"\"\"\n",
    "    Compute the Intersection over Union (IoU) for two binary masks.\n",
    "    Assumes both masks are binary with values 0 or 255.\n",
    "    \"\"\"\n",
    "    mask_pred_bool = mask_pred.astype(bool)\n",
    "    mask_gt_bool = mask_gt.astype(bool)\n",
    "    intersection = np.logical_and(mask_pred_bool, mask_gt_bool).sum()\n",
    "    union = np.logical_or(mask_pred_bool, mask_gt_bool).sum()\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "def ensure_dir(dir_path):\n",
    "    \"\"\"Create directory if it doesn't exist.\"\"\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "# ---------- Device Setup ----------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ---------- Load Models ----------\n",
    "\n",
    "# 1. Load U2-Net (ONNX) with GPU support if available\n",
    "u2net_path = os.path.join(\"models\", \"u2net.onnx\")\n",
    "providers = onnxruntime.get_available_providers()\n",
    "if \"CUDAExecutionProvider\" in providers:\n",
    "    u2net_session = onnxruntime.InferenceSession(u2net_path, providers=[\"CUDAExecutionProvider\"])\n",
    "    print(\"U2-Net using CUDAExecutionProvider\")\n",
    "else:\n",
    "    u2net_session = onnxruntime.InferenceSession(u2net_path)\n",
    "    print(\"U2-Net using CPU ExecutionProvider\")\n",
    "\n",
    "# 2. Load SAM model using its registry and move to the proper device\n",
    "sam_checkpoint = os.path.join(\"models\", \"sam_vit_h_4b8939.pth\")\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "# ---------- Setup Directories for Saving Results ----------\n",
    "\n",
    "# Directories for input images and ground truth masks.\n",
    "image_dir = \"DUT-OMRON-image\"\n",
    "mask_dir = \"DUT-OMRON-mask\"\n",
    "\n",
    "# Directories to save results (filenames remain the same as original).\n",
    "u2net_result_dir = os.path.join(\"models\", \"u2net_result\")\n",
    "sam_result_dir = os.path.join(\"models\", \"sam_result\")\n",
    "ensure_dir(u2net_result_dir)\n",
    "ensure_dir(sam_result_dir)\n",
    "\n",
    "# CSV file to log comparison results.\n",
    "csv_filename = \"compare_scores.csv\"\n",
    "\n",
    "# ---------- Processing and Evaluation ----------\n",
    "\n",
    "# Get list of images (assuming common image extensions)\n",
    "image_paths = sorted(glob(os.path.join(image_dir, \"*.*\")))\n",
    "iou_u2net_list = []\n",
    "iou_sam_list = []\n",
    "results = []\n",
    "\n",
    "# Create a tqdm progress bar.\n",
    "pbar = tqdm(image_paths, total=len(image_paths), desc=\"Processing images\")\n",
    "\n",
    "for i, image_path in enumerate(pbar):\n",
    "    # Update the progress bar postfix to show the count\n",
    "    pbar.set_postfix_str(f\"{i+1}/{len(image_paths)} complete\")\n",
    "\n",
    "    # Use the original filename for saving\n",
    "    filename = os.path.basename(image_path)\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "    gt_mask_path = os.path.join(mask_dir, basename + \".png\")  # Adjust extension if needed\n",
    "\n",
    "    # Read image and ground truth mask\n",
    "    image = cv2.imread(image_path)\n",
    "    gt_mask = cv2.imread(gt_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None or gt_mask is None:\n",
    "        print(f\"Skipping {basename}: could not read image or mask.\")\n",
    "        continue\n",
    "\n",
    "    # --- U2-Net Inference ---\n",
    "    input_tensor, orig_size = preprocess_for_u2net(image)\n",
    "    input_name = u2net_session.get_inputs()[0].name\n",
    "    pred = u2net_session.run(None, {input_name: input_tensor})[0]\n",
    "    u2net_mask = postprocess_u2net(pred, orig_size)\n",
    "\n",
    "    # Save U2-Net result using the original filename\n",
    "    u2net_save_path = os.path.join(u2net_result_dir, filename)\n",
    "    cv2.imwrite(u2net_save_path, u2net_mask)\n",
    "\n",
    "    # --- SAM Inference ---\n",
    "    masks = mask_generator.generate(image)\n",
    "    sam_mask = select_largest_mask(masks)\n",
    "    if sam_mask is None:\n",
    "        print(f\"No mask generated by SAM for {basename}.\")\n",
    "        continue\n",
    "\n",
    "    # Save SAM result using the original filename\n",
    "    sam_save_path = os.path.join(sam_result_dir, filename)\n",
    "    cv2.imwrite(sam_save_path, sam_mask)\n",
    "\n",
    "    # --- Evaluation (IoU) ---\n",
    "    gt_mask_bin = (gt_mask > 0).astype(np.uint8) * 255\n",
    "    iou_u2net = compute_iou(u2net_mask, gt_mask_bin)\n",
    "    iou_sam = compute_iou(sam_mask, gt_mask_bin)\n",
    "    iou_u2net_list.append(iou_u2net)\n",
    "    iou_sam_list.append(iou_sam)\n",
    "\n",
    "    results.append([filename, iou_u2net, iou_sam])\n",
    "    tqdm.write(f\"Image: {basename} | U2-Net IoU: {iou_u2net:.4f} | SAM IoU: {iou_sam:.4f}\")\n",
    "\n",
    "# Write CSV file with header: Image, U2-Net IoU, SAM IoU.\n",
    "with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Image\", \"U2-Net IoU\", \"SAM IoU\"])\n",
    "    writer.writerows(results)\n",
    "\n",
    "# ---------- Summary of Results ----------\n",
    "if iou_u2net_list and iou_sam_list:\n",
    "    avg_iou_u2net = np.mean(iou_u2net_list)\n",
    "    avg_iou_sam = np.mean(iou_sam_list)\n",
    "    print(\"\\n--- Overall Performance ---\")\n",
    "    print(f\"Average U2-Net IoU: {avg_iou_u2net:.4f}\")\n",
    "    print(f\"Average SAM IoU: {avg_iou_sam:.4f}\")\n",
    "else:\n",
    "    print(\"No valid results to summarize.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa2585-0a33-47d6-88b2-988073f29c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
